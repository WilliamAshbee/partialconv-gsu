================ Training Loss (Tue Aug 27 15:40:10 2019) ================
world size: 1
model created
================ Training Loss (Tue Aug 27 15:45:39 2019) ================
world size: 1
model created
================ Training Loss (Tue Aug 27 15:46:58 2019) ================
world size: 1
================ Training Loss (Tue Aug 27 15:47:26 2019) ================
world size: 1
model created
training/val dataset created
started training
Epoch: [0][0/20019]	Time 22.723 (22.723)	Data 2.520 (2.520)	Loss 7.3504 (7.3504)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Epoch: [0][10/20019]	Time 0.652 (3.625)	Data 0.000 (1.218)	Loss 7.0006 (9.9170)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.284)
Epoch: [0][20/20019]	Time 0.648 (2.213)	Data 0.000 (0.659)	Loss 7.0084 (8.5405)	Prec@1 0.000 (0.149)	Prec@5 0.000 (0.298)
Epoch: [0][30/20019]	Time 0.649 (1.712)	Data 0.000 (0.459)	Loss 7.6102 (8.2609)	Prec@1 0.000 (0.101)	Prec@5 0.000 (0.252)
Epoch: [0][40/20019]	Time 0.680 (1.459)	Data 0.004 (0.357)	Loss 6.8940 (8.0674)	Prec@1 0.000 (0.076)	Prec@5 0.000 (0.229)
Epoch: [0][50/20019]	Time 0.647 (1.301)	Data 0.001 (0.295)	Loss 6.9464 (7.8425)	Prec@1 0.000 (0.061)	Prec@5 0.000 (0.245)
Epoch: [0][60/20019]	Time 0.700 (1.197)	Data 0.000 (0.254)	Loss 6.8966 (7.6902)	Prec@1 1.562 (0.077)	Prec@5 1.562 (0.231)
Epoch: [0][70/20019]	Time 0.681 (1.122)	Data 0.000 (0.224)	Loss 6.9095 (7.5818)	Prec@1 0.000 (0.066)	Prec@5 0.000 (0.242)
Epoch: [0][80/20019]	Time 0.658 (1.066)	Data 0.000 (0.202)	Loss 6.9024 (7.4989)	Prec@1 0.000 (0.077)	Prec@5 0.000 (0.270)
Epoch: [0][90/20019]	Time 0.630 (1.023)	Data 0.000 (0.184)	Loss 6.9152 (7.4357)	Prec@1 0.000 (0.069)	Prec@5 0.000 (0.275)
Epoch: [0][100/20019]	Time 0.676 (0.989)	Data 0.000 (0.170)	Loss 6.9233 (7.3835)	Prec@1 0.000 (0.077)	Prec@5 0.000 (0.294)
Epoch: [0][110/20019]	Time 0.654 (0.960)	Data 0.000 (0.159)	Loss 6.8977 (7.3408)	Prec@1 0.000 (0.070)	Prec@5 0.000 (0.296)
Epoch: [0][120/20019]	Time 0.681 (0.936)	Data 0.000 (0.149)	Loss 6.9100 (7.3052)	Prec@1 0.000 (0.077)	Prec@5 0.000 (0.297)
Epoch: [0][130/20019]	Time 0.699 (0.917)	Data 0.000 (0.141)	Loss 6.9079 (7.2747)	Prec@1 0.000 (0.072)	Prec@5 0.000 (0.298)
Epoch: [0][140/20019]	Time 0.655 (0.900)	Data 0.000 (0.134)	Loss 6.9104 (7.2487)	Prec@1 0.000 (0.066)	Prec@5 0.000 (0.299)
Epoch: [0][150/20019]	Time 0.685 (0.885)	Data 0.000 (0.128)	Loss 6.9089 (7.2263)	Prec@1 0.000 (0.083)	Prec@5 0.000 (0.310)
Epoch: [0][160/20019]	Time 0.712 (0.872)	Data 0.002 (0.123)	Loss 6.9106 (7.2070)	Prec@1 0.000 (0.087)	Prec@5 1.562 (0.330)
Epoch: [0][170/20019]	Time 0.656 (0.861)	Data 0.000 (0.118)	Loss 6.9121 (7.1895)	Prec@1 0.000 (0.082)	Prec@5 0.000 (0.338)
Epoch: [0][180/20019]	Time 0.683 (0.850)	Data 0.011 (0.114)	Loss 6.9196 (7.1742)	Prec@1 0.000 (0.078)	Prec@5 1.562 (0.337)
Epoch: [0][190/20019]	Time 0.707 (0.841)	Data 0.000 (0.110)	Loss 6.9075 (7.1603)	Prec@1 0.000 (0.074)	Prec@5 0.000 (0.344)
Epoch: [0][200/20019]	Time 0.677 (0.833)	Data 0.000 (0.107)	Loss 6.9108 (7.1480)	Prec@1 0.000 (0.070)	Prec@5 0.000 (0.334)
Epoch: [0][210/20019]	Time 0.677 (0.825)	Data 0.000 (0.104)	Loss 6.9165 (7.1367)	Prec@1 0.000 (0.074)	Prec@5 0.000 (0.326)
Epoch: [0][220/20019]	Time 0.689 (0.818)	Data 0.000 (0.101)	Loss 6.9032 (7.1263)	Prec@1 0.000 (0.071)	Prec@5 0.000 (0.332)
Epoch: [0][230/20019]	Time 0.664 (0.812)	Data 0.000 (0.098)	Loss 6.9237 (7.1172)	Prec@1 0.000 (0.068)	Prec@5 0.000 (0.345)
Epoch: [0][240/20019]	Time 0.689 (0.806)	Data 0.000 (0.096)	Loss 6.9127 (7.1086)	Prec@1 0.000 (0.065)	Prec@5 0.000 (0.331)
Epoch: [0][250/20019]	Time 0.637 (0.801)	Data 0.000 (0.094)	Loss 6.9034 (7.1006)	Prec@1 0.000 (0.081)	Prec@5 0.000 (0.349)
Epoch: [0][260/20019]	Time 0.660 (0.796)	Data 0.000 (0.092)	Loss 6.9113 (7.0933)	Prec@1 0.000 (0.078)	Prec@5 0.000 (0.347)
Epoch: [0][270/20019]	Time 0.680 (0.791)	Data 0.000 (0.090)	Loss 6.9066 (7.0865)	Prec@1 0.000 (0.081)	Prec@5 0.000 (0.340)
Epoch: [0][280/20019]	Time 0.683 (0.787)	Data 0.000 (0.088)	Loss 6.8991 (7.0801)	Prec@1 0.000 (0.078)	Prec@5 0.000 (0.339)
================ Training Loss (Mon Sep  2 20:30:35 2019) ================
world size: 1
model created
training/val dataset created
started training
Epoch: [0][0/20019]	Time 22.427 (22.427)	Data 1.232 (1.232)	Loss 7.2440 (7.2440)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
================ Training Loss (Tue Sep  3 10:22:35 2019) ================
world size: 1
model created
training/val dataset created
started training
================ Training Loss (Tue Sep  3 10:47:48 2019) ================
world size: 1
model created
training/val dataset created
started training
Epoch: [0][0/20019]	Time 27.202 (27.202)	Data 1.013 (1.013)	Loss 7.2988 (7.2988)	Prec@1 0.000 (0.000)	Prec@5 1.562 (1.562)
Epoch: [0][10/20019]	Time 0.648 (4.694)	Data 0.001 (0.405)	Loss 7.0966 (9.3244)	Prec@1 0.000 (0.000)	Prec@5 1.562 (0.568)
Epoch: [0][20/20019]	Time 0.650 (2.769)	Data 0.001 (0.233)	Loss 6.9146 (8.2235)	Prec@1 0.000 (0.074)	Prec@5 0.000 (0.595)
Epoch: [0][30/20019]	Time 0.651 (2.085)	Data 0.001 (0.172)	Loss 6.9410 (7.8345)	Prec@1 0.000 (0.050)	Prec@5 3.125 (0.554)
Epoch: [0][40/20019]	Time 0.644 (1.735)	Data 0.001 (0.140)	Loss 7.0495 (7.7573)	Prec@1 0.000 (0.038)	Prec@5 0.000 (0.534)
Epoch: [0][50/20019]	Time 0.626 (1.523)	Data 0.002 (0.121)	Loss 6.9520 (7.6012)	Prec@1 0.000 (0.153)	Prec@5 0.000 (0.551)
Epoch: [0][60/20019]	Time 0.652 (1.380)	Data 0.001 (0.108)	Loss 6.9188 (7.4906)	Prec@1 0.000 (0.128)	Prec@5 0.000 (0.538)
Epoch: [0][70/20019]	Time 0.656 (1.278)	Data 0.001 (0.098)	Loss 6.9533 (7.4097)	Prec@1 0.000 (0.132)	Prec@5 1.562 (0.506)
================ Training Loss (Tue Sep  3 10:50:35 2019) ================
world size: 1
model created
training/val dataset created
started training
Epoch: [0][0/20019]	Time 7.145 (7.145)	Data 0.967 (0.967)	Loss 7.1603 (7.1603)	Prec@1 0.000 (0.000)	Prec@5 1.562 (1.562)
Epoch: [0][10/20019]	Time 0.653 (1.549)	Data 0.001 (0.426)	Loss 7.6540 (15.6293)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.284)
Epoch: [0][20/20019]	Time 0.663 (1.122)	Data 0.001 (0.243)	Loss 6.8857 (14.2594)	Prec@1 0.000 (0.000)	Prec@5 3.125 (0.670)
Epoch: [0][30/20019]	Time 0.645 (0.970)	Data 0.002 (0.178)	Loss 6.9016 (11.9099)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.454)
Epoch: [0][40/20019]	Time 0.663 (0.893)	Data 0.002 (0.145)	Loss 6.9145 (10.6900)	Prec@1 0.000 (0.038)	Prec@5 0.000 (0.381)
Epoch: [0][50/20019]	Time 0.657 (0.846)	Data 0.001 (0.124)	Loss 6.9121 (9.9511)	Prec@1 0.000 (0.061)	Prec@5 0.000 (0.398)
Epoch: [0][60/20019]	Time 0.667 (0.814)	Data 0.001 (0.111)	Loss 6.9122 (9.4522)	Prec@1 0.000 (0.077)	Prec@5 0.000 (0.384)
Epoch: [0][70/20019]	Time 0.637 (0.792)	Data 0.002 (0.101)	Loss 6.9314 (9.0946)	Prec@1 0.000 (0.088)	Prec@5 0.000 (0.352)
Epoch: [0][80/20019]	Time 0.665 (0.776)	Data 0.001 (0.094)	Loss 6.8984 (8.8263)	Prec@1 0.000 (0.077)	Prec@5 0.000 (0.367)
================ Training Loss (Tue Sep  3 10:58:54 2019) ================
world size: 1
model created
================ Training Loss (Tue Sep  3 11:02:46 2019) ================
world size: 1
model created
training/val dataset created
Test: [0/782]	Time 3.625 (3.625)	Loss 6.7766 (6.7766)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [10/782]	Time 0.237 (0.843)	Loss 7.1071 (6.9416)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [20/782]	Time 0.226 (0.550)	Loss 7.0572 (6.9289)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [30/782]	Time 0.227 (0.446)	Loss 6.9674 (6.9283)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [40/782]	Time 0.234 (0.393)	Loss 6.9336 (6.9361)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [50/782]	Time 0.235 (0.361)	Loss 7.0532 (6.9353)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [60/782]	Time 0.235 (0.339)	Loss 6.7636 (6.9241)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [70/782]	Time 0.227 (0.324)	Loss 6.9175 (6.9249)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.088)
Test: [80/782]	Time 0.228 (0.312)	Loss 6.8432 (6.9235)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.077)
Test: [90/782]	Time 0.226 (0.303)	Loss 6.9280 (6.9269)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.069)
Test: [100/782]	Time 0.226 (0.296)	Loss 6.8829 (6.9317)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.062)
Test: [110/782]	Time 0.237 (0.291)	Loss 6.9184 (6.9296)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.056)
Test: [120/782]	Time 0.236 (0.286)	Loss 7.0224 (6.9313)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.052)
Test: [130/782]	Time 0.234 (0.281)	Loss 6.9553 (6.9312)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.048)
Test: [140/782]	Time 0.227 (0.278)	Loss 6.9175 (6.9272)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.211)
Test: [150/782]	Time 0.226 (0.275)	Loss 6.9815 (6.9269)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.197)
Test: [160/782]	Time 0.227 (0.272)	Loss 6.9056 (6.9274)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.184)
Test: [170/782]	Time 0.229 (0.269)	Loss 6.8624 (6.9270)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.174)
Test: [180/782]	Time 0.235 (0.267)	Loss 6.8954 (6.9259)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.164)
Test: [190/782]	Time 0.229 (0.265)	Loss 6.8822 (6.9273)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.155)
Test: [200/782]	Time 0.233 (0.264)	Loss 6.7847 (6.9257)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.148)
Test: [210/782]	Time 0.229 (0.262)	Loss 6.8322 (6.9271)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.141)
Test: [220/782]	Time 0.244 (0.261)	Loss 6.8474 (6.9250)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.134)
Test: [230/782]	Time 0.227 (0.259)	Loss 6.9678 (6.9282)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.129)
Test: [240/782]	Time 0.228 (0.259)	Loss 6.9380 (6.9267)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.123)
Test: [250/782]	Time 0.230 (0.258)	Loss 6.9047 (6.9262)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.118)
Test: [260/782]	Time 0.229 (0.257)	Loss 7.2349 (6.9276)	Prec@1 0.000 (0.293)	Prec@5 0.000 (0.419)
Test: [270/782]	Time 0.238 (0.256)	Loss 7.1870 (6.9282)	Prec@1 0.000 (0.283)	Prec@5 0.000 (0.404)
Test: [280/782]	Time 0.228 (0.256)	Loss 6.7187 (6.9285)	Prec@1 0.000 (0.272)	Prec@5 0.000 (0.389)
Test: [290/782]	Time 0.229 (0.255)	Loss 6.6816 (6.9287)	Prec@1 0.000 (0.263)	Prec@5 0.000 (0.376)
Test: [300/782]	Time 0.250 (0.254)	Loss 6.9468 (6.9254)	Prec@1 0.000 (0.254)	Prec@5 0.000 (0.405)
Test: [310/782]	Time 0.229 (0.253)	Loss 6.8388 (6.9260)	Prec@1 0.000 (0.246)	Prec@5 0.000 (0.392)
Test: [320/782]	Time 0.229 (0.253)	Loss 7.2020 (6.9228)	Prec@1 0.000 (0.243)	Prec@5 0.000 (0.540)
Test: [330/782]	Time 0.238 (0.252)	Loss 6.9748 (6.9205)	Prec@1 0.000 (0.236)	Prec@5 0.000 (0.524)
Test: [340/782]	Time 0.228 (0.252)	Loss 6.7146 (6.9196)	Prec@1 0.000 (0.229)	Prec@5 0.000 (0.509)
Test: [350/782]	Time 0.237 (0.251)	Loss 6.9969 (6.9211)	Prec@1 0.000 (0.223)	Prec@5 0.000 (0.494)
Test: [360/782]	Time 0.231 (0.251)	Loss 7.1421 (6.9223)	Prec@1 0.000 (0.216)	Prec@5 0.000 (0.480)
Test: [370/782]	Time 0.231 (0.250)	Loss 6.8042 (6.9219)	Prec@1 0.000 (0.211)	Prec@5 0.000 (0.472)
Test: [380/782]	Time 0.232 (0.250)	Loss 6.9750 (6.9236)	Prec@1 0.000 (0.205)	Prec@5 0.000 (0.459)
Test: [390/782]	Time 0.229 (0.249)	Loss 7.0373 (6.9229)	Prec@1 0.000 (0.200)	Prec@5 0.000 (0.448)
Test: [400/782]	Time 0.230 (0.249)	Loss 7.1748 (6.9233)	Prec@1 0.000 (0.195)	Prec@5 0.000 (0.436)
Test: [410/782]	Time 0.236 (0.248)	Loss 6.8066 (6.9242)	Prec@1 0.000 (0.190)	Prec@5 0.000 (0.426)
Test: [420/782]	Time 0.251 (0.248)	Loss 7.1327 (6.9274)	Prec@1 0.000 (0.186)	Prec@5 0.000 (0.416)
Test: [430/782]	Time 0.230 (0.248)	Loss 7.0193 (6.9289)	Prec@1 0.000 (0.181)	Prec@5 0.000 (0.479)
Test: [440/782]	Time 0.233 (0.247)	Loss 6.9334 (6.9289)	Prec@1 0.000 (0.177)	Prec@5 0.000 (0.468)
Test: [450/782]	Time 0.229 (0.247)	Loss 6.6966 (6.9282)	Prec@1 0.000 (0.173)	Prec@5 0.000 (0.457)
Test: [460/782]	Time 0.231 (0.247)	Loss 6.8928 (6.9291)	Prec@1 0.000 (0.169)	Prec@5 0.000 (0.447)
Test: [470/782]	Time 0.243 (0.247)	Loss 6.8389 (6.9293)	Prec@1 0.000 (0.166)	Prec@5 0.000 (0.438)
Test: [480/782]	Time 0.229 (0.246)	Loss 7.0476 (6.9284)	Prec@1 0.000 (0.162)	Prec@5 0.000 (0.435)
Test: [490/782]	Time 0.229 (0.246)	Loss 7.1289 (6.9292)	Prec@1 0.000 (0.159)	Prec@5 0.000 (0.426)
Test: [500/782]	Time 0.229 (0.246)	Loss 6.8872 (6.9304)	Prec@1 0.000 (0.156)	Prec@5 0.000 (0.418)
Test: [510/782]	Time 0.229 (0.245)	Loss 6.9978 (6.9314)	Prec@1 0.000 (0.153)	Prec@5 0.000 (0.410)
Test: [520/782]	Time 0.240 (0.245)	Loss 7.0495 (6.9304)	Prec@1 0.000 (0.150)	Prec@5 0.000 (0.408)
Test: [530/782]	Time 0.239 (0.245)	Loss 6.7237 (6.9302)	Prec@1 0.000 (0.147)	Prec@5 0.000 (0.400)
Test: [540/782]	Time 0.230 (0.245)	Loss 6.9631 (6.9305)	Prec@1 0.000 (0.144)	Prec@5 0.000 (0.393)
Test: [550/782]	Time 0.238 (0.244)	Loss 6.9456 (6.9301)	Prec@1 0.000 (0.142)	Prec@5 0.000 (0.386)
Test: [560/782]	Time 0.229 (0.244)	Loss 6.9927 (6.9307)	Prec@1 0.000 (0.139)	Prec@5 0.000 (0.379)
Test: [570/782]	Time 0.231 (0.244)	Loss 7.1222 (6.9301)	Prec@1 0.000 (0.137)	Prec@5 0.000 (0.479)
Test: [580/782]	Time 0.238 (0.244)	Loss 7.1302 (6.9298)	Prec@1 0.000 (0.134)	Prec@5 0.000 (0.471)
Test: [590/782]	Time 0.242 (0.244)	Loss 6.9163 (6.9277)	Prec@1 0.000 (0.132)	Prec@5 0.000 (0.563)
Test: [600/782]	Time 0.230 (0.244)	Loss 6.8288 (6.9279)	Prec@1 0.000 (0.130)	Prec@5 0.000 (0.554)
Test: [610/782]	Time 0.231 (0.243)	Loss 7.0093 (6.9267)	Prec@1 0.000 (0.128)	Prec@5 0.000 (0.547)
Test: [620/782]	Time 0.231 (0.243)	Loss 7.0114 (6.9267)	Prec@1 0.000 (0.126)	Prec@5 0.000 (0.538)
Test: [630/782]	Time 0.247 (0.243)	Loss 6.7355 (6.9269)	Prec@1 0.000 (0.124)	Prec@5 0.000 (0.530)
Test: [640/782]	Time 0.229 (0.243)	Loss 6.9460 (6.9261)	Prec@1 0.000 (0.124)	Prec@5 0.000 (0.600)
Test: [650/782]	Time 0.229 (0.243)	Loss 7.2243 (6.9252)	Prec@1 0.000 (0.122)	Prec@5 0.000 (0.590)
Test: [660/782]	Time 0.247 (0.243)	Loss 6.9480 (6.9251)	Prec@1 0.000 (0.121)	Prec@5 0.000 (0.582)
Test: [670/782]	Time 0.229 (0.242)	Loss 7.0147 (6.9260)	Prec@1 0.000 (0.119)	Prec@5 0.000 (0.573)
Test: [680/782]	Time 0.241 (0.242)	Loss 6.9425 (6.9268)	Prec@1 0.000 (0.117)	Prec@5 0.000 (0.564)
Test: [690/782]	Time 0.230 (0.242)	Loss 7.0153 (6.9265)	Prec@1 0.000 (0.115)	Prec@5 0.000 (0.556)
Test: [700/782]	Time 0.240 (0.242)	Loss 6.8546 (6.9265)	Prec@1 0.000 (0.114)	Prec@5 0.000 (0.548)
Test: [710/782]	Time 0.230 (0.242)	Loss 7.0426 (6.9274)	Prec@1 0.000 (0.112)	Prec@5 0.000 (0.541)
Test: [720/782]	Time 0.237 (0.242)	Loss 7.0232 (6.9261)	Prec@1 0.000 (0.111)	Prec@5 0.000 (0.533)
Test: [730/782]	Time 0.241 (0.242)	Loss 6.8484 (6.9264)	Prec@1 0.000 (0.109)	Prec@5 0.000 (0.526)
Test: [740/782]	Time 0.229 (0.241)	Loss 6.9367 (6.9247)	Prec@1 0.000 (0.108)	Prec@5 0.000 (0.552)
Test: [750/782]	Time 0.228 (0.241)	Loss 6.9106 (6.9247)	Prec@1 0.000 (0.106)	Prec@5 0.000 (0.545)
Test: [760/782]	Time 0.230 (0.241)	Loss 6.8074 (6.9247)	Prec@1 0.000 (0.105)	Prec@5 0.000 (0.538)
Test: [770/782]	Time 0.230 (0.241)	Loss 6.9904 (6.9248)	Prec@1 0.000 (0.103)	Prec@5 0.000 (0.531)
Test: [780/782]	Time 0.229 (0.241)	Loss 6.8492 (6.9238)	Prec@1 0.000 (0.102)	Prec@5 0.000 (0.524)
 * Prec@1 0.102 Prec@5 0.524================ Training Loss (Tue Sep  3 14:39:05 2019) ================
world size: 1
model created
training/val dataset created
started training
